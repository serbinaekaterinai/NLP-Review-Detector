{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d827980d-0c09-4b46-8cb0-3c9fc5f6f4dd",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "533803b6-91ec-4faa-a57e-4ca7192dc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "from nltk import WordNetLemmatizer # lemmatizer using WordNet\n",
    "from nltk.corpus import wordnet # imports WordNet\n",
    "from nltk import pos_tag # nltk's native part of speech tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4be5cb17-f005-465d-939b-f2babbb063b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fake reviews dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed7da3-dfe0-4207-b8f2-45d871c728a2",
   "metadata": {},
   "source": [
    "## Data Undersatding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78ea703a-88c1-4ccb-b6a4-9376358321d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Kindle_Store_5                  4730\n",
       "Books_5                         4370\n",
       "Pet_Supplies_5                  4254\n",
       "Home_and_Kitchen_5              4056\n",
       "Electronics_5                   3988\n",
       "Sports_and_Outdoors_5           3946\n",
       "Tools_and_Home_Improvement_5    3858\n",
       "Clothing_Shoes_and_Jewelry_5    3848\n",
       "Toys_and_Games_5                3794\n",
       "Movies_and_TV_5                 3588\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "034dc82e-b462-48fd-b1f2-5438d3fa94d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40432.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.256579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.144354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating\n",
       "count  40432.000000\n",
       "mean       4.256579\n",
       "std        1.144354\n",
       "min        1.000000\n",
       "25%        4.000000\n",
       "50%        5.000000\n",
       "75%        5.000000\n",
       "max        5.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17583586-ab05-4182-9acc-1d5e645fff49",
   "metadata": {},
   "source": [
    "## Text Preprocessing: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64443346-bda4-4529-b83c-606dec64b9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accessing and storing the content of the first comment in the 'text_' column\n",
    "first_doc = df['text_'].iloc[0]\n",
    "first_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00ec5139-a0c4-4595-8bfb-46d31d80c880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Love', 'this', '!', 'Well', 'made', ',', 'sturdy', ',', 'and', 'very', 'comfortable', '.', 'I', 'love', 'it', '!', 'Very', 'pretty']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word_tokenize(first_doc, language='english'))\n",
    "first_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efbbef3c-805e-489d-be1f-13db33ce83e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Love', 'this', '!', 'Well', 'made', ',', 'sturdy', ',', 'and', 'very', 'comfortable', '.', 'I', 'love', 'it', '!', 'Very', 'pretty'], ['love', 'it', ',', 'a', 'great', 'upgrade', 'from', 'the', 'original', '.', 'I', \"'ve\", 'had', 'mine', 'for', 'a', 'couple', 'of', 'years'], ['This', 'pillow', 'saved', 'my', 'back', '.', 'I', 'love', 'the', 'look', 'and', 'feel', 'of', 'this', 'pillow', '.'], ['Missing', 'information', 'on', 'how', 'to', 'use', 'it', ',', 'but', 'it', 'is', 'a', 'great', 'product', 'for', 'the', 'price', '!', 'I']]\n"
     ]
    }
   ],
   "source": [
    "#tokenizing the text data in the 'text_' column of df\n",
    "corpus = [word_tokenize(doc) for doc in df['text_']]\n",
    "print(corpus[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba09b430-09b6-4200-beb3-d7621552b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3099953,)\n"
     ]
    }
   ],
   "source": [
    "# flattening the list of tokenized words contained in the corpus list\n",
    "flattenedcorpus_tokens = pd.Series(list(itertools.chain(*corpus)))\n",
    "print(flattenedcorpus_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37c02735-9948-4809-88cc-ac066b5e2ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60431\n"
     ]
    }
   ],
   "source": [
    "dictionary = pd.Series(\n",
    "    flattenedcorpus_tokens.unique())\n",
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ba992-fb65-4556-b695-99c1a6ab073d",
   "metadata": {},
   "source": [
    "### Dealing with Stop words + lowecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffb84533-6248-4e04-a061-eafed487f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we']\n"
     ]
    }
   ],
   "source": [
    "# getting common stop words in english that we'll remove during tokenization/text normalization\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d7e856b-29a8-4999-8f1a-69dffbe017b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_step_normalizer(doc):\n",
    "    norm_text = [x.lower() for x in word_tokenize(doc) if ((x.isalpha()) & (x not in stop_words)) ]\n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3560f6c7-6fc0-4124-a81d-35074a2c2c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>tok_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>[love, well, made, sturdy, comfortable, i, lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>[love, great, upgrade, original, i, mine, coup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>[this, pillow, saved, back, i, love, look, fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>[missing, information, use, great, product, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>[very, nice, set, good, quality, we, set, two,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \\\n",
       "0  Love this!  Well made, sturdy, and very comfor...   \n",
       "1  love it, a great upgrade from the original.  I...   \n",
       "2  This pillow saved my back. I love the look and...   \n",
       "3  Missing information on how to use it, but it i...   \n",
       "4  Very nice set. Good quality. We have had the s...   \n",
       "\n",
       "                                            tok_norm  \n",
       "0  [love, well, made, sturdy, comfortable, i, lov...  \n",
       "1  [love, great, upgrade, original, i, mine, coup...  \n",
       "2  [this, pillow, saved, back, i, love, look, fee...  \n",
       "3  [missing, information, use, great, product, pr...  \n",
       "4  [very, nice, set, good, quality, we, set, two,...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tok_norm'] = df['text_'].apply(first_step_normalizer)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8469c572-5b25-4269-b3cb-1f69a35b8668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37936\n"
     ]
    }
   ],
   "source": [
    "norm_toks_flattened = pd.Series(list(\n",
    "    itertools.chain(*df['tok_norm'])))\n",
    "new_dictionary = norm_toks_flattened.unique()\n",
    "print(len(new_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97d37a6b-8813-435d-9530-7e1c4054933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60431\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fe415-1382-431f-94b9-28d5e1e74587",
   "metadata": {},
   "source": [
    "- Process removed 22.500 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b86f15b-bc61-4d7f-a92e-de5226998736",
   "metadata": {},
   "source": [
    "## Text Preprocessing: Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c6357-4aa0-42e7-abd5-499dc453ac42",
   "metadata": {},
   "source": [
    "#### We created function which takes in untokenized document and returns fully normalized token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97728c8b-7f8e-493a-871d-ac2ca5afa8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc(doc):\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    def pos_tagger(nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:         \n",
    "            return None\n",
    "        \n",
    "    # remove stop words and punctuations, then lower case\n",
    "    doc_norm = [tok.lower() for tok in word_tokenize(doc) if ((tok.isalpha()) & (tok not in stop_words)) ]\n",
    "\n",
    "    # creates list of tuples with tokens and POS tags in wordnet format\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tag(doc_norm))) \n",
    "    doc_norm = [wnl.lemmatize(token, pos) for token, pos in wordnet_tagged if pos is not None]\n",
    "    \n",
    "    return doc_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac37d0-1b5b-46af-8985-6c6e9379e5a3",
   "metadata": {},
   "source": [
    "### Applying text Tokenization/Normalization to whole body of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4024578d-fa1f-4db6-8d7d-cbbc6d186cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_normalized_corpus = df['text_'].apply(process_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7b114d7-6d8c-41ec-8277-d1e6285c1df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [love, well, make, sturdy, comfortable, i, lov...\n",
       "1    [love, great, upgrade, original, i, mine, coup...\n",
       "2    [pillow, save, back, i, love, look, feel, pillow]\n",
       "3    [miss, information, use, great, product, price...\n",
       "4         [very, nice, set, good, quality, set, month]\n",
       "Name: text_, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_normalized_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fbae9fd1-5eb7-4b3e-a91d-bd2cfc1b6840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31587"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_fully_norm = pd.Series(list(itertools.chain(*fully_normalized_corpus)))\n",
    "len(flattened_fully_norm.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efd0d37e-ed5c-4a78-a0dd-eedddeb09e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 love\n",
       "1                 well\n",
       "2                 make\n",
       "3               sturdy\n",
       "4          comfortable\n",
       "              ...     \n",
       "1272945    comfortable\n",
       "1272946           shoe\n",
       "1272947           wear\n",
       "1272948           walk\n",
       "1272949            day\n",
       "Length: 1272950, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_fully_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "acf7910a-c799-4f9a-8f17-210afb22c7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        love well make sturdy comfortable i love very ...\n",
       "1           love great upgrade original i mine couple year\n",
       "2                 pillow save back i love look feel pillow\n",
       "3               miss information use great product price i\n",
       "4                     very nice set good quality set month\n",
       "                               ...                        \n",
       "40427    i read review say bra run small i order band c...\n",
       "40428    i sure exactly little large small size i think...\n",
       "40429    wear hood wear hood wear jacket hood system re...\n",
       "40430    i like nothing dress reason i give star i orde...\n",
       "40431    i work wed industry work long day foot outside...\n",
       "Name: text_, Length: 40432, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flattening the lists\n",
    "fnc_output = fully_normalized_corpus.apply(\" \".join)\n",
    "fnc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12cca8-477e-4485-8258-e208d99e54c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
