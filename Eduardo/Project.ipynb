{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d827980d-0c09-4b46-8cb0-3c9fc5f6f4dd",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533803b6-91ec-4faa-a57e-4ca7192dc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be5cb17-f005-465d-939b-f2babbb063b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fake reviews dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed7da3-dfe0-4207-b8f2-45d871c728a2",
   "metadata": {},
   "source": [
    "## Data Undersatding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ea703a-88c1-4ccb-b6a4-9376358321d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kindle_Store_5                  4730\n",
       "Books_5                         4370\n",
       "Pet_Supplies_5                  4254\n",
       "Home_and_Kitchen_5              4056\n",
       "Electronics_5                   3988\n",
       "Sports_and_Outdoors_5           3946\n",
       "Tools_and_Home_Improvement_5    3858\n",
       "Clothing_Shoes_and_Jewelry_5    3848\n",
       "Toys_and_Games_5                3794\n",
       "Movies_and_TV_5                 3588\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "034dc82e-b462-48fd-b1f2-5438d3fa94d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40432.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.256579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.144354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating\n",
       "count  40432.000000\n",
       "mean       4.256579\n",
       "std        1.144354\n",
       "min        1.000000\n",
       "25%        4.000000\n",
       "50%        5.000000\n",
       "75%        5.000000\n",
       "max        5.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17583586-ab05-4182-9acc-1d5e645fff49",
   "metadata": {},
   "source": [
    "## Text Preprocessing: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21d63507-d2a1-49ff-a5fc-879a191194c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the text data in the 'text_' column of df\n",
    "corpus = [word_tokenize(doc) for doc in df['text_']]\n",
    "\n",
    "# getting common stop words in english that we'll remove during tokenization/text normalization\n",
    "stop_words = stopwords.words('english')\n",
    "corpus_no_stopwords = []\n",
    "for words in corpus:\n",
    "    docs = [x.lower() for x in words if ((x.isalpha()) & (x not in stop_words))]\n",
    "    corpus_no_stopwords.append(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c671ab9-1944-48ff-96db-c374083e0f0c",
   "metadata": {},
   "source": [
    "## Lemmantizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8703adb6-185e-474d-8d4d-6e9d4c702340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(corpus):\n",
    "    lem = WordNetLemmatizer()\n",
    "    \n",
    "    def pos_tagger(nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:         \n",
    "            return None\n",
    "    lemmatized_corpus = []\n",
    "    for sentence in corpus:\n",
    "        pos_tags = pos_tag(sentence)\n",
    "        lemmatized_sentence = []\n",
    "        for word, tag in pos_tags:\n",
    "            pos = pos_tagger(tag)\n",
    "            if pos is not None:\n",
    "                lemmatized_word = lem.lemmatize(word, pos)\n",
    "            else:\n",
    "                lemmatized_word = lem.lemmatize(word)\n",
    "            lemmatized_sentence.append(lemmatized_word)\n",
    "        lemmatized_corpus.append(lemmatized_sentence)\n",
    "    \n",
    "    return lemmatized_corpus\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "747e8fba-94e9-4fe4-b8e2-e8a68e842d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_corpus = lemmatizer(corpus_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72435717-6b57-4004-96aa-9c3158368198",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_lemm_corpus = [' '.join(x) for x in lemmatized_corpus]\n",
    "df['text_preproccesed'] = pd.Series(data=joined_lemm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6394d54f-244e-4fb7-9264-927bb1c0f9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>text_preproccesed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>love well make sturdy comfortable i love very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>love great upgrade original i mine couple year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>this pillow save back i love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>miss information use great product price i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>very nice set good quality we set two month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40427</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I had read some reviews saying that this bra r...</td>\n",
       "      <td>i read review say bra run small i order two ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40428</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I wasn't sure exactly what it would be. It is ...</td>\n",
       "      <td>i sure exactly would it little large small siz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40429</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>You can wear the hood by itself, wear it with ...</td>\n",
       "      <td>you wear hood wear hood wear jacket without ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40430</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>I liked nothing about this dress. The only rea...</td>\n",
       "      <td>i like nothing dress the reason i give star i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40431</th>\n",
       "      <td>Clothing_Shoes_and_Jewelry_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>I work in the wedding industry and have to wor...</td>\n",
       "      <td>i work wed industry work long day foot outside...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40432 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category  rating label  \\\n",
       "0                Home_and_Kitchen_5     5.0    CG   \n",
       "1                Home_and_Kitchen_5     5.0    CG   \n",
       "2                Home_and_Kitchen_5     5.0    CG   \n",
       "3                Home_and_Kitchen_5     1.0    CG   \n",
       "4                Home_and_Kitchen_5     5.0    CG   \n",
       "...                             ...     ...   ...   \n",
       "40427  Clothing_Shoes_and_Jewelry_5     4.0    OR   \n",
       "40428  Clothing_Shoes_and_Jewelry_5     5.0    CG   \n",
       "40429  Clothing_Shoes_and_Jewelry_5     2.0    OR   \n",
       "40430  Clothing_Shoes_and_Jewelry_5     1.0    CG   \n",
       "40431  Clothing_Shoes_and_Jewelry_5     5.0    OR   \n",
       "\n",
       "                                                   text_  \\\n",
       "0      Love this!  Well made, sturdy, and very comfor...   \n",
       "1      love it, a great upgrade from the original.  I...   \n",
       "2      This pillow saved my back. I love the look and...   \n",
       "3      Missing information on how to use it, but it i...   \n",
       "4      Very nice set. Good quality. We have had the s...   \n",
       "...                                                  ...   \n",
       "40427  I had read some reviews saying that this bra r...   \n",
       "40428  I wasn't sure exactly what it would be. It is ...   \n",
       "40429  You can wear the hood by itself, wear it with ...   \n",
       "40430  I liked nothing about this dress. The only rea...   \n",
       "40431  I work in the wedding industry and have to wor...   \n",
       "\n",
       "                                       text_preproccesed  \n",
       "0      love well make sturdy comfortable i love very ...  \n",
       "1         love great upgrade original i mine couple year  \n",
       "2          this pillow save back i love look feel pillow  \n",
       "3             miss information use great product price i  \n",
       "4            very nice set good quality we set two month  \n",
       "...                                                  ...  \n",
       "40427  i read review say bra run small i order two ba...  \n",
       "40428  i sure exactly would it little large small siz...  \n",
       "40429  you wear hood wear hood wear jacket without ho...  \n",
       "40430  i like nothing dress the reason i give star i ...  \n",
       "40431  i work wed industry work long day foot outside...  \n",
       "\n",
       "[40432 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98eab3-fdcc-4c63-8fca-3feff9297fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ab7a1-0906-46d2-9495-15613c6927c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17273570-6549-4ba7-83f0-f177b5d9d6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972b4ad-a4fe-4f2c-9ce1-c7ef28fc8282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b2543-ec7d-40d2-b7d4-f8962c2f4f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e9261-0029-4651-a807-0fb6c4083cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10542c-3ae2-4480-b56f-13a2426f8174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410ba78c-54a2-4bda-92c3-c06938d3a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_unique = pd.Series(flattenedcorpus_tokens.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba09b430-09b6-4200-beb3-d7621552b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3099953,)\n"
     ]
    }
   ],
   "source": [
    "# flattening the list of tokenized words contained in the corpus list\n",
    "flattenedcorpus_tokens = pd.Series(list(itertools.chain(*corpus)))\n",
    "print(flattenedcorpus_tokens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ba992-fb65-4556-b695-99c1a6ab073d",
   "metadata": {},
   "source": [
    "### Dealing with Stop words + lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b597f3-ff88-487b-a201-a42fdd72694b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47953"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_no_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3560f6c7-6fc0-4124-a81d-35074a2c2c1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_step_normalizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtok_norm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[43mfirst_step_normalizer\u001b[49m)\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'first_step_normalizer' is not defined"
     ]
    }
   ],
   "source": [
    "df['tok_norm'] = df['text_'].apply(first_step_normalizer)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469c572-5b25-4269-b3cb-1f69a35b8668",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_toks_flattened = pd.Series(list(\n",
    "    itertools.chain(*df['tok_norm'])))\n",
    "new_dictionary = norm_toks_flattened.unique()\n",
    "print(len(new_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d37a6b-8813-435d-9530-7e1c4054933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fe415-1382-431f-94b9-28d5e1e74587",
   "metadata": {},
   "source": [
    "- Process removed 22.500 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b86f15b-bc61-4d7f-a92e-de5226998736",
   "metadata": {},
   "source": [
    "## Text Preprocessing: Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c6357-4aa0-42e7-abd5-499dc453ac42",
   "metadata": {},
   "source": [
    "#### We created function which takes in untokenized document and returns fully normalized token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b98c0-cf85-42f3-a14c-6201c8321ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97728c8b-7f8e-493a-871d-ac2ca5afa8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc(doc):\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    def pos_tagger(nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:         \n",
    "            return None\n",
    "        \n",
    "    # remove stop words and punctuations, then lower case\n",
    "    doc_norm = [tok.lower() for tok in word_tokenize(doc) if ((tok.isalpha()) & (tok not in stop_words)) ]\n",
    "\n",
    "    # creates list of tuples with tokens and POS tags in wordnet format\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tag(doc_norm))) \n",
    "    doc_norm = [wnl.lemmatize(token, pos) for token, pos in wordnet_tagged if pos is not None]\n",
    "    \n",
    "    return doc_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac37d0-1b5b-46af-8985-6c6e9379e5a3",
   "metadata": {},
   "source": [
    "### Applying text Tokenization/Normalization to whole body of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024578d-fa1f-4db6-8d7d-cbbc6d186cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_normalized_corpus = df['text_'].apply(process_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b114d7-6d8c-41ec-8277-d1e6285c1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_normalized_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae9fd1-5eb7-4b3e-a91d-bd2cfc1b6840",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_fully_norm = pd.Series(list(itertools.chain(*fully_normalized_corpus)))\n",
    "len(flattened_fully_norm.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd0d37e-ed5c-4a78-a0dd-eedddeb09e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_fully_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7910a-c799-4f9a-8f17-210afb22c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening the lists\n",
    "fnc_output = fully_normalized_corpus.apply(\" \".join)\n",
    "fnc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12cca8-477e-4485-8258-e208d99e54c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
